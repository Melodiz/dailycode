{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po1qcjD2lW4A"
      },
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a>, <a href=\"https://www.hse.ru/en/staff/sara/\" target=\"_blank\">Saraa Ali</a>  ¬©2025 onwards</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "**[<font size=6>üöóAuto</font>](https://www.kaggle.com/t/9225c9c3931741ad9e384d5ba0180cc3)**. [**Instructions**](https://colab.research.google.com/drive/1owkYjuRGkx050LQnM3b3yTzd0Dr2XbeV) for running Colabs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB_RPHLJloqz"
      },
      "source": [
        "<small>**(Optional) CONSENT.** <mark>[ X ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purposes. We understand that sharing is optional and this decision will not affect our grade in any way. <font color=gray><i>(If ok with sharing your Colab for educational purposes, leave \"X\" in the check box.)</i></font></small>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToKDfNMabFMF",
        "outputId": "5afcdaca-f3d7-4a57-90b9-db6414c35ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "timer started\n",
            "CPU times: user 6.18 s, sys: 1 s, total: 7.19 s\n",
            "Wall time: 24.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import pandas as pd, time, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print('timer started')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=10000, precision=4, edgeitems=20, suppress=True)\n",
        "pd.set_option('display.max_rows', 100, 'display.max_columns', 100, 'display.max_colwidth', 100, 'display.precision', 2, 'display.max_rows', 4)\n",
        "\n",
        "db = fetch_openml('BNG(auto_price)')   # load databunch (dictionary)\n",
        "tX = pd.DataFrame(db['data'], columns=db['feature_names'])\n",
        "tX.symboling = tX.symboling.astype('float')\n",
        "tX['price'] = db['target']\n",
        "YCols = ['city-mpg','highway-mpg','price']  # 3 targets\n",
        "tY = tX[YCols]\n",
        "tX.drop(YCols, axis=1, inplace=True)\n",
        "# tY = pd.Series(db['target'], name='price')\n",
        "tX, vX, tY, DO_NOT_USE = train_test_split(tX, tY, train_size=0.7, random_state=0, shuffle=True)\n",
        "# ToCSV(DO_NOT_USE, 'testY')   # Students cannot use these test values\n",
        "del DO_NOT_USE\n",
        "tX\n",
        "tY\n",
        "tmr = Timer() # runtime limit (in seconds). Add all of your code after the timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxjQQnTAlsog",
        "outputId": "6ffa146f-cba1-4209-c81e-2a163ef1fcec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "timer started\n"
          ]
        }
      ],
      "source": [
        "tmr = Timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MPlcR1YSIY9"
      },
      "source": [
        "<hr color=red>\n",
        "\n",
        "<font size=5>‚è≥</font> <strong><font color=orange size=5>Your Code, Documentation, Ideas and Timer - All Start Here...</font></strong>\n",
        "\n",
        "**Student's Section** (between ‚è≥ symbols): add your code and documentation here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpyLNt3god0c"
      },
      "source": [
        "## **Task 1. Preprocessing Pipeline**\n",
        "\n",
        "Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc.\n",
        "1. Why did you choose these elements? (Something in EDA, prior experience,...? Btw, EDA is not required)\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30xYIFXAnaPE"
      },
      "source": [
        "**Student's answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJRwzqHob4o"
      },
      "source": [
        "## **Task 2. Modeling Approach**\n",
        "Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful.\n",
        "\n",
        "1. How did these decisions guide you in modeling?\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6ZjgtWnb58"
      },
      "source": [
        "**Student's answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_U8i_Erl0oE"
      },
      "source": [
        "Below is an **improved baseline** with feature engineering that should significantly outperform the simple baseline.\n",
        "\n",
        "### Improvements implemented:\n",
        "1. **Log transformation**: Apply log(1+|x|) to numerical features to handle skewed distributions\n",
        "2. **Polynomial features**: Generate degree-2 polynomial features including interactions\n",
        "3. **Better encoding**: Drop redundant binary features to reduce multicollinearity\n",
        "4. **Stronger regularization**: Increase alpha to handle the expanded feature space\n",
        "5. **Robust imputation**: Handle missing values before transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkz9ySewbTU-",
        "outputId": "e3be39a0-ab02-480c-e4c8-2335b2771882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In-sample R^2 = 0.3245\n"
          ]
        }
      ],
      "source": [
        "# IMPROVED BASELINE WITH FEATURE ENGINEERING\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = tX.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = tX.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {len(numerical_cols)} columns\")\n",
        "\n",
        "# Enhanced numerical transformer with log transforms and polynomial features\n",
        "def safe_log_transform(X):\n",
        "    \"\"\"Apply log(1+x) transform to handle zeros and negatives\"\"\"\n",
        "    return np.log1p(np.abs(X))\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('log_transform', FunctionTransformer(safe_log_transform, validate=False)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='if_binary'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create a full pipeline with Ridge regression (higher alpha for regularization with more features)\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', MultiOutputRegressor(Ridge(alpha=10.0, random_state=0)))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "print(\"\\nTraining improved model...\")\n",
        "model_pipeline.fit(tX, tY)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_score = model_pipeline.score(tX, tY)\n",
        "print(f'In-sample R^2 = {train_score:.4f}')\n",
        "\n",
        "# Generate predictions for validation set\n",
        "print(\"\\nGenerating predictions...\")\n",
        "pY_improved = pd.DataFrame(model_pipeline.predict(vX), index=vX.index, columns=YCols)\n",
        "ToCSV(pY_improved, 'Auto_improved_baseline')\n",
        "print(\"Predictions saved to 'Auto_improved_baseline.csv'\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample predictions:\")\n",
        "pY_improved.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Version with PCA\n",
        "\n",
        "Adding PCA to reduce dimensionality and capture the most important patterns from the polynomial features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ADVANCED BASELINE WITH PCA FOR DIMENSIONALITY REDUCTION\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Enhanced numerical transformer with PCA\n",
        "numerical_transformer_pca = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('log_transform', FunctionTransformer(safe_log_transform, validate=False)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)),\n",
        "    ('pca', PCA(n_components=0.95, random_state=0))  # Keep 95% of variance\n",
        "])\n",
        "\n",
        "# Combine preprocessing with PCA\n",
        "preprocessor_pca = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer_pca, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create pipeline with PCA\n",
        "model_pipeline_pca = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_pca),\n",
        "    ('regressor', MultiOutputRegressor(Ridge(alpha=5.0, random_state=0)))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "print(\"\\nTraining advanced model with PCA...\")\n",
        "model_pipeline_pca.fit(tX, tY)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_score_pca = model_pipeline_pca.score(tX, tY)\n",
        "print(f'In-sample R^2 (with PCA) = {train_score_pca:.4f}')\n",
        "\n",
        "# Generate predictions for validation set\n",
        "print(\"\\nGenerating predictions...\")\n",
        "pY_advanced = pd.DataFrame(model_pipeline_pca.predict(vX), index=vX.index, columns=YCols)\n",
        "ToCSV(pY_advanced, 'Auto_advanced_baseline')\n",
        "print(\"Predictions saved to 'Auto_advanced_baseline.csv'\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample predictions:\")\n",
        "pY_advanced.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trying Other Allowed Models\n",
        "\n",
        "Competition allows: Linear Models, SVC/SVM, and Nearest Neighbors. Let's try a combination approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRY SVM REGRESSOR (SVR)\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Use simpler preprocessing for SVR (it's slower with many features)\n",
        "numerical_transformer_svr = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),  # Only interactions\n",
        "    ('pca', PCA(n_components=50, random_state=0))  # Reduce to 50 components for speed\n",
        "])\n",
        "\n",
        "preprocessor_svr = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer_svr, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create pipeline with SVR (RBF kernel)\n",
        "model_pipeline_svr = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_svr),\n",
        "    ('regressor', MultiOutputRegressor(SVR(kernel='rbf', C=10.0, epsilon=0.1)))\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "print(\"\\nTraining SVR model...\")\n",
        "model_pipeline_svr.fit(tX, tY)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_score_svr = model_pipeline_svr.score(tX, tY)\n",
        "print(f'In-sample R^2 (SVR) = {train_score_svr:.4f}')\n",
        "\n",
        "# Generate predictions for validation set\n",
        "print(\"\\nGenerating predictions...\")\n",
        "pY_svr = pd.DataFrame(model_pipeline_svr.predict(vX), index=vX.index, columns=YCols)\n",
        "ToCSV(pY_svr, 'Auto_svr_baseline')\n",
        "print(\"Predictions saved to 'Auto_svr_baseline.csv'\")\n",
        "\n",
        "print(\"\\nSample predictions:\")\n",
        "pY_svr.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison Summary\n",
        "\n",
        "Compare all models and select the best one for submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMPARE ALL MODELS\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Improved Baseline (Ridge + PolyFeatures):     R¬≤ = {train_score:.4f}\")\n",
        "print(f\"Advanced Baseline (Ridge + PCA):              R¬≤ = {train_score_pca:.4f}\")\n",
        "print(f\"SVR Model (RBF Kernel):                       R¬≤ = {train_score_svr:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Determine best model\n",
        "scores = {\n",
        "    'Improved': train_score,\n",
        "    'Advanced (PCA)': train_score_pca,\n",
        "    'SVR': train_score_svr\n",
        "}\n",
        "best_model = max(scores, key=scores.get)\n",
        "print(f\"\\n‚úì Best in-sample performance: {best_model} (R¬≤ = {scores[best_model]:.4f})\")\n",
        "print(\"\\nSubmission files generated:\")\n",
        "print(\"  - Auto_improved_baseline.csv\")\n",
        "print(\"  - Auto_advanced_baseline.csv\")\n",
        "print(\"  - Auto_svr_baseline.csv\")\n",
        "print(\"\\nRecommendation: Try all three on Kaggle and see which performs best on LB!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzBsjCvS_kEw"
      },
      "source": [
        "# **References:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      },
      "source": [
        "1. Remember to cite your sources here as well! At the least, your textbook should be cited. Google Scholar allows you to effortlessly copy/paste an APA citation format for books and publications. Also cite StackOverflow, package documentation, and other meaningful internet resources to help your peers learn from these (and to avoid plagiarism claims)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-DJaBpAG8_P"
      },
      "source": [
        "<font color=green><h4><b>$\\epsilon$. LLM Documentation if used</b></h4></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AONzG2gWG9H_"
      },
      "source": [
        "<font color=red><b>Your answer here.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoF2GoB_QGw9"
      },
      "source": [
        "<font size=5>‚åõ</font> <strong><font color=orange size=5>Do not exceed competition's runtime limit!</font></strong>\n",
        "\n",
        "<hr color=red>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD1sdgYbNWQA",
        "outputId": "11d62fe6-9464-49ec-e83c-8306e09676bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Runtime is 28 sec\n"
          ]
        }
      ],
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nnK53pcbVY0"
      },
      "source": [
        "## üí°**Starter Ideas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn7E4huqbY-I"
      },
      "source": [
        "1. Tune model hyperparameters and try different allowed models\n",
        "1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n",
        "1. Try higher order feature interactions and polynomial features on a small subsample. Then identify key features or select key principal components. The final model can be trained on a larger or even full training sample. You can use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the feature set\n",
        "1. Do a thorough EDA: look for feature augmentations that result in linear decision boundaries between pairs of classes.\n",
        "1. Evaluate predictions and focus on poorly predicted \"groups\":\n",
        "  1. Strongest errors. E.g. the model is very confident about the wrong label\n",
        "1. Do scatter plots show piecewise linear shape? Can a separate linear model be used on each support, or can the pattern be linearized via transformations?\n",
        "1. Try modeling each output separately from inputs or from a other modeled output\n",
        "1. Try stepwise selection and regularization and remove \"unimportant\" features from final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZPw3K1ymkYw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
