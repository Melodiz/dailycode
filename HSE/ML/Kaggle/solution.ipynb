{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3673f2f",
   "metadata": {},
   "source": [
    "\n",
    "# Linear Models Solution â€” Price Prediction (Kaggle-ready)\n",
    "\n",
    "This notebook builds a **high-performing linear baseline** fully compliant with the competition rules:\n",
    "- Uses only **linear models** (Ridge and SGDRegressor with L1/ElasticNet penalties).\n",
    "- Emphasizes **feature engineering**, regularization, and cross-validation.\n",
    "- Produces a **`submission.csv`**.\n",
    "\n",
    "> **Assumptions**: You have `train.csv` and `test.csv` with columns:  \n",
    "`carat, depth, table, x, y, z, cut, color, clarity, price` (no `price` in `test.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1c2c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge, SGDRegressor, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Global seeds for reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "267b1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paths (edit if needed) ===\n",
    "DATA_PATH = \"XY_diamonds.csv\"\n",
    "SUBMISSION_PATH = 'submission.csv'\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"Cannot find {DATA_PATH}. Please put train.csv in working directory.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9060565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled rows: 160000 / 200000\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv(DATA_PATH)\n",
    "has_price = raw[\"price\"].notna()\n",
    "print(\"Labeled rows:\", has_price.sum(), \"/\", len(raw))\n",
    "\n",
    "train = raw.loc[has_price].copy()\n",
    "test  = raw.loc[~has_price].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11a553cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Add domain-inspired features and handle zero/NaN dimensions.\"\"\"\n",
    "    def __init__(self):\n",
    "        # canonical ordinal maps (best is larger score)\n",
    "        self.cut_map = {'F':1,'G':2,'V':3,'P':4,'I':5}  # Fair<Good<VeryGood<Premium<Ideal\n",
    "        self.color_map = {'J':1,'I':2,'H':3,'G':4,'F':5,'E':6,'D':7}  # J worst -> D best\n",
    "        self.clarity_map = {\n",
    "            'I1':1, 'SI2':2, 'SI1':3, 'VS2':4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8\n",
    "        }  # ascending quality\n",
    "        \n",
    "        self.numeric_cols_ = None\n",
    "        self.categorical_cols_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # remember column sets\n",
    "        cols = list(X.columns)\n",
    "        self.categorical_cols_ = [c for c in ['cut','color','clarity'] if c in cols]\n",
    "        self.numeric_cols_ = [c for c in cols if c not in self.categorical_cols_ + ['price']]\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_div(a, b):\n",
    "        out = np.divide(a, b, out=np.full_like(a, np.nan, dtype='float64'), where=(b!=0)&(~np.isnan(b)))\n",
    "        return out\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Ensure numeric types for dimensions\n",
    "        for c in ['carat','depth','table','x','y','z']:\n",
    "            if c in X.columns:\n",
    "                X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "\n",
    "        # Zero-as-missing flags\n",
    "        for c in ['x','y','z']:\n",
    "            if c in X.columns:\n",
    "                X[f'{c}_is_zero'] = (X[c] == 0).astype(int)\n",
    "                X.loc[X[c] == 0, c] = np.nan\n",
    "\n",
    "        # Basic geometric features\n",
    "        X['volume'] = X[['x','y','z']].prod(axis=1, skipna=True)\n",
    "        X['area_xy'] = X['x'] * X['y']\n",
    "        X['size_sum'] = X[['x','y','z']].sum(axis=1, skipna=True)\n",
    "        X['size_mean'] = X[['x','y','z']].mean(axis=1, skipna=True)\n",
    "        X['size_max'] = X[['x','y','z']].max(axis=1, skipna=True)\n",
    "        X['size_min'] = X[['x','y','z']].min(axis=1, skipna=True)\n",
    "\n",
    "        # Ratios and derived metrics\n",
    "        X['depth_pct'] = 100.0 * self._safe_div(X['z'], (X['x'] + X['y'])/2.0)\n",
    "        X['xy_ratio']  = self._safe_div(X['x'], X['y'])\n",
    "        X['z_to_xy']   = self._safe_div(X['z'], np.sqrt(X['x'] * X['y']))\n",
    "        X['carat_per_vol'] = self._safe_div(X['carat'], X['volume'])\n",
    "        # New ratios\n",
    "        X['table_over_depth'] = self._safe_div(X['table'], X['depth'])\n",
    "        X['z_over_carat'] = self._safe_div(X['z'], X['carat'])\n",
    "        X['mean_xy'] = (X['x'] + X['y']) / 2.0\n",
    "        X['deviation_depth_pct_from_ideal'] = (X['depth_pct'] - 61.5).abs()\n",
    "        X['deviation_table_from_ideal'] = (X['table'] - 57.0).abs()\n",
    "        X['elongation'] = self._safe_div(X[['x','y']].max(axis=1, skipna=True), X[['x','y']].min(axis=1, skipna=True))\n",
    "\n",
    "        # Logs to handle skew\n",
    "        for c in ['carat','x','y','z','volume','area_xy','size_sum','size_mean','deviation_depth_pct_from_ideal','deviation_table_from_ideal']:\n",
    "            X[f'log1p_{c}'] = np.log1p(X[c])\n",
    "\n",
    "        # Interactions (controlled)\n",
    "        X['carat_x_depth']   = X['carat'] * X['depth']\n",
    "        X['carat_x_table']   = X['carat'] * X['table']\n",
    "        X['carat_x_depthpct']= X['carat'] * X['depth_pct']\n",
    "        X['depth_x_table']   = X['depth'] * X['table']\n",
    "        # New interactions\n",
    "        X['carat_x_volume'] = X['carat'] * X['volume']\n",
    "        X['carat_x_log_volume'] = X['carat'] * X['log1p_volume']\n",
    "        X['depthpct_x_table'] = X['depth_pct'] * X['table']\n",
    "        X['xy_ratio_x_carat'] = X['xy_ratio'] * X['carat']\n",
    "        X['elongation_x_carat'] = X['elongation'] * X['carat']\n",
    "\n",
    "        # Ordinal quality scores (plus keep raw categories for OHE)\n",
    "        if 'cut' in X.columns:\n",
    "            X['cut_score'] = X['cut'].map(self.cut_map).astype(float)\n",
    "        if 'color' in X.columns:\n",
    "            X['color_score'] = X['color'].map(self.color_map).astype(float)\n",
    "        if 'clarity' in X.columns:\n",
    "            X['clarity_score'] = X['clarity'].map(self.clarity_map).astype(float)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5701200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clip numeric features to [low_q, high_q] learned from training data only.\"\"\"\n",
    "    def __init__(self, numeric_cols: List[str], low=0.005, high=0.995):\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for c in self.numeric_cols:\n",
    "            if c in X.columns:\n",
    "                lo, hi = X[c].quantile(self.low), X[c].quantile(self.high)\n",
    "                if not np.isfinite(lo):\n",
    "                    lo = X[c].min()\n",
    "                if not np.isfinite(hi):\n",
    "                    hi = X[c].max()\n",
    "                self.bounds_[c] = (lo, hi)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for c, (lo, hi) in self.bounds_.items():\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].clip(lo, hi)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b59f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering\n",
    "fe = FeatureEngineer()\n",
    "train_fe = fe.fit_transform(train)\n",
    "test_fe  = fe.transform(test)\n",
    "\n",
    "# Identify columns for preprocessing\n",
    "cat_cols = [c for c in ['cut','color','clarity'] if c in train_fe.columns]\n",
    "num_cols = [c for c in train_fe.columns if c not in cat_cols + ['price']]\n",
    "\n",
    "# Winsorize numeric columns (fit on train only; apply to both)\n",
    "win = Winsorizer(numeric_cols=num_cols, low=0.005, high=0.995)\n",
    "train_fe[num_cols] = win.fit_transform(train_fe[num_cols])\n",
    "test_fe[num_cols]  = win.transform(test_fe[num_cols])\n",
    "\n",
    "# Preprocessor: impute + scale numerics; impute + OHE categories\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), num_cols),\n",
    "        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore'))]), cat_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d9476b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def get_models():\n",
    "    # Ridge with a broad alpha search\n",
    "    ridge = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
    "    ridge_alphas = np.logspace(-3, 4, 20)\n",
    "\n",
    "    # SGDRegressor variants support sparse matrices (after OHE), good for L1/EN\n",
    "    sgd_l1 = SGDRegressor(loss='squared_error', penalty='l1', random_state=RANDOM_STATE, max_iter=4000, early_stopping=True)\n",
    "    sgd_en = SGDRegressor(loss='squared_error', penalty='elasticnet', random_state=RANDOM_STATE, max_iter=4000, early_stopping=True)\n",
    "\n",
    "    grids = {\n",
    "        'ridge': {'model': ridge, 'params': {'model__alpha': ridge_alphas}},\n",
    "        'sgd_l1': {'model': sgd_l1, 'params': {'model__alpha': [1e-5, 3e-5, 1e-4, 3e-4, 1e-3]}},\n",
    "        'sgd_en': {'model': sgd_en, 'params': {'model__alpha': [1e-5, 3e-5, 1e-4, 3e-4, 1e-3], 'model__l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]}},\n",
    "    }\n",
    "    return grids\n",
    "\n",
    "def cross_validated_oof_predictions(X, y, preprocessor, model, params, n_splits=5):\n",
    "    # y is on price scale; we'll log-transform inside this function for training\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    models = []\n",
    "    mae_scores = []\n",
    "\n",
    "    fold = 0\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        fold += 1\n",
    "        X_tr, X_va = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_va = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # pipeline: preprocess -> model, trained on log1p(price)\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('prep', preprocessor),\n",
    "            ('model', clone(model))\n",
    "        ])\n",
    "\n",
    "        # do inner grid search for this fold (optimize MAE)\n",
    "        gs = GridSearchCV(pipe, params, scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "        # log-transform target for training\n",
    "        y_tr_log = np.log1p(y_tr.values)\n",
    "        gs.fit(X_tr, y_tr_log)\n",
    "\n",
    "        best = gs.best_estimator_\n",
    "        pred_log = best.predict(X_va)\n",
    "        pred = np.expm1(pred_log)\n",
    "        oof[val_idx] = pred\n",
    "\n",
    "        score = mae(y_va.values, pred)\n",
    "        mae_scores.append(score)\n",
    "        models.append(best)\n",
    "        print(f\"Fold {fold}: MAE={score:.4f} | Best params: {gs.best_params_}\")\n",
    "\n",
    "    print(f\"CV MAE mean={np.mean(mae_scores):.4f}  std={np.std(mae_scores):.4f}\")\n",
    "    return oof, models, mae_scores\n",
    "\n",
    "def blend_predictions(preds_list, maes):\n",
    "    # inverse-variance-style weighting (weights ~ 1 / mae^2)\n",
    "    inv_var = np.array([1.0/(m**2 + 1e-12) for m in maes])\n",
    "    w = inv_var / inv_var.sum()\n",
    "    blended = np.sum([w[i]*preds_list[i] for i in range(len(preds_list))], axis=0)\n",
    "    return blended, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc182f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RIDGE ===\n",
      "Fold 1: MAE=670.9265 | Best params: {'model__alpha': np.float64(0.001)}\n",
      "Fold 2: MAE=672.1233 | Best params: {'model__alpha': np.float64(0.001)}\n",
      "Fold 3: MAE=671.0159 | Best params: {'model__alpha': np.float64(0.001)}\n",
      "Fold 4: MAE=669.9550 | Best params: {'model__alpha': np.float64(0.002335721469090121)}\n",
      "Fold 5: MAE=680.2884 | Best params: {'model__alpha': np.float64(0.001)}\n",
      "CV MAE mean=672.8618  std=3.7763\n",
      "\n",
      "=== SGD_L1 ===\n",
      "Fold 1: MAE=684.3987 | Best params: {'model__alpha': 3e-05}\n",
      "Fold 2: MAE=681.5689 | Best params: {'model__alpha': 1e-05}\n",
      "Fold 3: MAE=686.3450 | Best params: {'model__alpha': 3e-05}\n",
      "Fold 4: MAE=686.7716 | Best params: {'model__alpha': 1e-05}\n",
      "Fold 5: MAE=693.9497 | Best params: {'model__alpha': 1e-05}\n",
      "CV MAE mean=686.6068  std=4.1054\n",
      "\n",
      "=== SGD_EN ===\n",
      "Fold 1: MAE=684.6866 | Best params: {'model__alpha': 0.0003, 'model__l1_ratio': 0.1}\n",
      "Fold 2: MAE=681.6892 | Best params: {'model__alpha': 3e-05, 'model__l1_ratio': 0.5}\n",
      "Fold 3: MAE=686.2839 | Best params: {'model__alpha': 3e-05, 'model__l1_ratio': 0.75}\n",
      "Fold 4: MAE=686.7562 | Best params: {'model__alpha': 1e-05, 'model__l1_ratio': 0.9}\n",
      "Fold 5: MAE=693.9025 | Best params: {'model__alpha': 1e-05, 'model__l1_ratio': 0.25}\n",
      "CV MAE mean=686.6637  std=4.0301\n",
      "\n",
      "OOF MAE by model:\n",
      "  ridge: 672.8618\n",
      "  sgd_l1: 686.6068\n",
      "  sgd_en: 686.6637\n",
      "Blending weights (ridge, sgd_l1, sgd_en): [0.3424 0.3288 0.3288]\n",
      "\n",
      "Blended OOF MAE: 672.2536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = train_fe['price']\n",
    "X = train_fe.drop(columns=['price'])\n",
    "\n",
    "model_grids = get_models()\n",
    "\n",
    "oof_dict = {}\n",
    "models_dict = {}\n",
    "rmse_dict = {}\n",
    "\n",
    "for name, spec in model_grids.items():\n",
    "    print(f\"\\n=== {name.upper()} ===\")\n",
    "    oof, models, scores = cross_validated_oof_predictions(X, y, preprocessor, spec['model'], spec['params'], n_splits=5)\n",
    "    oof_dict[name] = oof\n",
    "    models_dict[name] = models\n",
    "    rmse_dict[name] = np.mean(scores)\n",
    "\n",
    "# Blend OOF predictions\n",
    "preds_list = [oof_dict['ridge'], oof_dict['sgd_l1'], oof_dict['sgd_en']]\n",
    "rmses = [rmse_dict['ridge'], rmse_dict['sgd_l1'], rmse_dict['sgd_en']]\n",
    "blended_oof, weights = blend_predictions(preds_list, rmses)\n",
    "\n",
    "print(\"\\nOOF MAE by model:\")\n",
    "for k,v in rmse_dict.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "print(f\"Blending weights (ridge, sgd_l1, sgd_en): {weights.round(4)}\")\n",
    "\n",
    "oof_mae = mae(y.values, blended_oof)\n",
    "print(f\"\\nBlended OOF MAE: {oof_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8a63b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refit complete for all base models.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Refit best single model per type on full data (select the best fold estimator by its val MAE)\n",
    "final_models = []\n",
    "\n",
    "# For each model type, pick the fold-model with the lowest MAE and refit on FULL data\n",
    "for name in ['ridge', 'sgd_l1', 'sgd_en']:\n",
    "    specs = model_grids[name]\n",
    "    # Find best fold index\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_scores = []\n",
    "    idx = 0\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        y_va = y.iloc[val_idx]\n",
    "        preds_va = oof_dict[name][val_idx]\n",
    "        fold_scores.append(mae(y_va.values, preds_va))\n",
    "    best_fold = int(np.argmin(fold_scores))\n",
    "\n",
    "    best_estimator = models_dict[name][best_fold]\n",
    "    # Refit on ALL data with the same hyperparameters\n",
    "    params = best_estimator.get_params()\n",
    "    model_refit = Pipeline(steps=[('prep', preprocessor), ('model', clone(best_estimator.named_steps['model']))])\n",
    "    model_refit.named_steps['model'].set_params(**{k.replace('model__',''): v for k,v in best_estimator.get_params().items() if k.startswith('model__')})\n",
    "\n",
    "    y_log = np.log1p(y.values)\n",
    "    model_refit.fit(X, y_log)\n",
    "    final_models.append((name, model_refit))\n",
    "\n",
    "print(\"Refit complete for all base models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b9fd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict with each final model\n",
    "test_preds_each = []\n",
    "for name, mdl in final_models:\n",
    "    pred_log = mdl.predict(test_fe)\n",
    "    pred = np.expm1(pred_log)\n",
    "    test_preds_each.append(pred)\n",
    "\n",
    "# Blend using the same weights computed from OOF\n",
    "blended_test = np.sum([weights[i]*test_preds_each[i] for i in range(len(test_preds_each))], axis=0)\n",
    "\n",
    "# Clean-up predictions\n",
    "blended_test = np.maximum(blended_test, 0.0)  # no negative prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7686814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>841.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15151.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>887.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>569.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>881.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     price\n",
       "0   1    841.48\n",
       "1   2  15151.85\n",
       "2   3    887.59\n",
       "3   4    569.83\n",
       "4   5    881.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Determine ID column if present, else create 1..N ids\n",
    "id_col = 'id' if 'id' in test.columns else None\n",
    "if id_col:\n",
    "    ids = test[id_col].astype(int).values\n",
    "else:\n",
    "    ids = np.arange(1, len(test) + 1, dtype=int)\n",
    "\n",
    "# Build submission, clip/round per baseline reference\n",
    "submission = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'price': blended_test\n",
    "})\n",
    "submission['price'] = submission['price'].clip(lower=10).round(2)\n",
    "\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Saved: {SUBMISSION_PATH}\")\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df30bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mean_xy</td>\n",
       "      <td>-13.348361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>log1p_area_xy</td>\n",
       "      <td>11.916922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>11.417620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>log1p_y</td>\n",
       "      <td>-10.447299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>2.435368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>log1p_size_mean</td>\n",
       "      <td>-1.882236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>log1p_carat</td>\n",
       "      <td>1.478119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>log1p_volume</td>\n",
       "      <td>-1.474877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>log1p_x</td>\n",
       "      <td>-1.474384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>size_mean</td>\n",
       "      <td>1.298084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>log1p_size_sum</td>\n",
       "      <td>1.073196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>size_sum</td>\n",
       "      <td>1.006985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>size_max</td>\n",
       "      <td>0.750928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>area_xy</td>\n",
       "      <td>-0.746719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xy_ratio_x_carat</td>\n",
       "      <td>-0.709337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>carat_x_log_volume</td>\n",
       "      <td>-0.656599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>log1p_z</td>\n",
       "      <td>0.466336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>elongation_x_carat</td>\n",
       "      <td>0.420704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>carat_x_depthpct</td>\n",
       "      <td>0.297858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>carat_x_depth</td>\n",
       "      <td>-0.222863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>clarity_I1</td>\n",
       "      <td>-0.221305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>clarity_score</td>\n",
       "      <td>0.202933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>z_to_xy</td>\n",
       "      <td>-0.193475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>table</td>\n",
       "      <td>-0.182883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>depth_pct</td>\n",
       "      <td>0.166571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature       coef\n",
       "21             mean_xy -13.348361\n",
       "30       log1p_area_xy  11.916922\n",
       "4                    y  11.417620\n",
       "27             log1p_y -10.447299\n",
       "3                    x   2.435368\n",
       "32     log1p_size_mean  -1.882236\n",
       "25         log1p_carat   1.478119\n",
       "29        log1p_volume  -1.474877\n",
       "26             log1p_x  -1.474384\n",
       "12           size_mean   1.298084\n",
       "31      log1p_size_sum   1.073196\n",
       "11            size_sum   1.006985\n",
       "13            size_max   0.750928\n",
       "10             area_xy  -0.746719\n",
       "42    xy_ratio_x_carat  -0.709337\n",
       "40  carat_x_log_volume  -0.656599\n",
       "28             log1p_z   0.466336\n",
       "43  elongation_x_carat   0.420704\n",
       "37    carat_x_depthpct   0.297858\n",
       "35       carat_x_depth  -0.222863\n",
       "59          clarity_I1  -0.221305\n",
       "46       clarity_score   0.202933\n",
       "17             z_to_xy  -0.193475\n",
       "2                table  -0.182883\n",
       "15           depth_pct   0.166571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Inspect top coefficients for the Ridge model (best fold refit on full data)\n",
    "try:\n",
    "    ridge_model = [m for n,m in final_models if n=='ridge'][0]\n",
    "    # get feature names from preprocessor\n",
    "    num_cols = [c for c in train_fe.columns if c not in ['price','cut','color','clarity']]\n",
    "    cat_cols = [c for c in ['cut','color','clarity'] if c in train_fe.columns]\n",
    "    ohe = ridge_model.named_steps['prep'].named_transformers_['cat']\n",
    "    cat_features = list(ohe.get_feature_names_out(cat_cols)) if len(cat_cols)>0 else []\n",
    "    feature_names = num_cols + cat_features\n",
    "\n",
    "    coef = ridge_model.named_steps['model'].coef_\n",
    "    # When StandardScaler + OneHotEncoder -> sparse design; coef_ is dense vector\n",
    "    coef_df = pd.DataFrame({'feature': feature_names, 'coef': coef[:len(feature_names)]})\n",
    "    coef_df['abs'] = coef_df['coef'].abs()\n",
    "    coef_df = coef_df.sort_values('abs', ascending=False).head(25)\n",
    "    display(coef_df[['feature','coef']])\n",
    "except Exception as e:\n",
    "    print(\"Coefficient inspection skipped:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melcond",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
